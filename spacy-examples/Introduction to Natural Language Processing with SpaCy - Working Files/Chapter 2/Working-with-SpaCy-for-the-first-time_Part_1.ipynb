{"nbformat": 4, "cells": [{"source": "### Dependencies for this notebook:\n<br>\n* pip install spacy, pandas, matplotlib\n* python -m spacy.en.download\n\n    ", "cell_type": "markdown", "metadata": {"_datascience": {}}}, {"outputs": [], "source": "from IPython.display import SVG, display\nimport spacy\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n%matplotlib inline", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}, {"outputs": [], "source": "#encode some text as uncode\ntext = u\"I'm executing this code on an Apple Computer.\"\n\n#instantiate a language model\n#to download language model: python -m spacy.en.download \nnlp = spacy.load('en') # or spacy.en.English()\n\n#create a document\ndocument = nlp(text)", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}, {"outputs": [], "source": "for function in nlp.pipeline:\n    print function", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}, {"outputs": [], "source": "### Modifying the Language Model\ndef identify_starwars(doc):\n    for token in doc:\n        if token.text == u'starwars':\n            token.tag_ = u'NNP'\n\ndef return_pipeline(nlp):\n    return [nlp.tagger, nlp.parser, nlp.matcher, nlp.entity, identify_starwars]\n\ntext = u\"I loved all of the starwars movies\"\ncustom_nlp = spacy.load('en', create_pipeline=return_pipeline)\nnew_document = custom_nlp(text)\n\nfor function in custom_nlp.pipeline:\n    print function", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}, {"outputs": [], "source": "texts = [u'You have brains in your head.'] * 10000\n\n\nfor doc in nlp.pipe(texts,n_threads=4):\n    doc.is_parsed", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}, {"outputs": [], "source": "### Deploying Model on Many Texts with .pipe\nruntimes = {}\n\nfor thread_count in [1,2,3,4,8]:\n    t0 =  datetime.now() \n    \n    #Create generator of processed documents\n    processed_documents = nlp.pipe(texts,n_threads=thread_count)\n    \n    #Iterate over generator\n    for doc in processed_documents: \n        \n        #pipeline is only run once we access the generator\n        doc.is_parsed \n    \n    t1 = datetime.now()\n    runtimes[thread_count] = (t1 - t0).total_seconds()\n    \nax = pd.Series(runtimes).plot(kind = 'bar')\nax.set_ylabel(\"Runtime (Seconds) with N Threads\")\nplt.show()", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}, {"source": "### Accessing Tokens and Spans", "cell_type": "markdown", "metadata": {"_datascience": {}}}, {"outputs": [], "source": "import pandas as pd\ndef info(obj):\n    return {'type':type(obj),'__str__': str(obj)}\n\n\ntext = u\"\"\"spaCy excels at large-scale information extraction tasks. \nIt's written from the ground up in carefully memory-managed Cython. \"\"\"\ndocument = nlp(text)\ntoken = document[0]\nspan = document[0:3]\n\n\npd.DataFrame(map(info, [token,span,document]))", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}, {"source": "### Sentence boundary detection", "cell_type": "markdown", "metadata": {"_datascience": {}}}, {"outputs": [], "source": "print document.sents\nprint\nfor sent in document.sents:\n    print sent", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}, {"source": "### Tokenization", "cell_type": "markdown", "metadata": {"_datascience": {}}}, {"outputs": [], "source": "for token in document:\n    print token", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}, {"source": "### Morphological decomposition", "cell_type": "markdown", "metadata": {"_datascience": {}}}, {"outputs": [], "source": "token = document[13]\nprint \"text: %s\" % token.text\nprint \"suffix: %s\" % token.suffix_ \nprint \"lemma: %s\" % token.lemma_", "execution_count": 2, "cell_type": "code", "metadata": {"collapsed": false, "_datascience": {}}}, {"source": "### Part of Speech Tagging", "cell_type": "markdown", "metadata": {"_datascience": {}}}, {"outputs": [], "source": "#Part of speech and Dependency tagging\nattrs = map(lambda token: {\n                     \"token\":token\n                   , \"part of speech\":token.pos_\n                   , \"Dependency\" : token.dep_}\n                    , document)\npd.DataFrame(attrs)", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}, {"source": "### Noun Chunking", "cell_type": "markdown", "metadata": {"_datascience": {}}}, {"outputs": [], "source": "print \"noun chunks: {}\".format(list(document.noun_chunks))", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}, {"source": "### Named Entity Recognition", "cell_type": "markdown", "metadata": {"_datascience": {}}}, {"outputs": [], "source": "ents = [(ent, ent.root.ent_type_) for ent in document.ents]\nprint \"entities: {}\".format(ents)", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}, {"source": "### Text Similarity (Using Word Vectors)", "cell_type": "markdown", "metadata": {"_datascience": {}}}, {"outputs": [], "source": "#document, span, and token similarity\ndef plot_similarities(similarities, target):\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    f, ax = plt.subplots(1)\n    index = range(len(similarities))\n    ax.barh(index, similarities)\n    ax.set_yticks([i + 0. for i in index])\n    ax.set_yticklabels(document2)\n    ax.grid(axis='x')\n    ax.set_title(\"Similarity to '{}'\".format(target))\n    plt.show()\n    return ax\n    \n    \ncomputer = nlp(u'computer')\ndocument2 = nlp(u'You might be using a machine running Windows')\nsimilarities = map(lambda token: token.similarity(computer),document2)\nax = plot_similarities(similarities, computer)\n\n\n\n\n    ", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}, {"outputs": [], "source": "", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}, {"outputs": [], "source": "", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}, {"outputs": [], "source": "", "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_datascience": {}}}], "metadata": {"language_info": {"pygments_lexer": "ipython2", "codemirror_mode": {"name": "ipython", "version": 2}, "version": "2.7.12", "file_extension": ".py", "name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python"}, "_datascience": {"notebookId": 747}, "kernelspec": {"language": "python", "name": "python2", "display_name": "Python 2"}}, "nbformat_minor": 2}